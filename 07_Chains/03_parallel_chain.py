from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint
from dotenv import load_dotenv
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain.schema.runnable import RunnableParallel

load_dotenv()

llm1= HuggingFaceEndpoint(
    repo_id="openai/gpt-oss-20b",
    task="text-generation"
)

llm2= HuggingFaceEndpoint(
    repo_id="openai/gpt-oss-120b",
    task="text-generation"
)

model1 = ChatHuggingFace(llm=llm1)

model2 = ChatHuggingFace(llm=llm2)

prompt1 = PromptTemplate(
    template="Generate a detailed, professional and research paper based notes on the following text \n{text}",
    input_variables=['text']
)

prompt2 = PromptTemplate(
    template="Genearate a 5 question answer from the following text \n{text}",
    input_variables=['text']
)

prompt3 = PromptTemplate(
    template="Merge the provided notes and question answer into a single document \nnotes -> {notes} and QA -> {question_answer}",
    input_variables=["notes", "question_answer"]
)

parser = StrOutputParser()

parallel_chain = RunnableParallel({
    "notes": prompt1 | model1 | parser,
    "question_answer": prompt2 | model2 | parser
})

merge_chain = prompt3 | model2 | parser

chain = parallel_chain | merge_chain

text = '''
# ğŸ¤– Transformers â€“ The Deepâ€‘Learning Engine Behind Largeâ€‘Language Models  
*A Selfâ€‘Contained, Beginnerâ€‘Friendly Guide (Expanded & Researchâ€‘Ready)*  

---

### ğŸš€ Why this Post?  
From the first paper on *Attention Is All You Need* to todayâ€™s GPTâ€‘4, Transformers have reshaped every AI field that cares about sequence data. Yet, the terminology and math still feel like a black box for many. This article turns the murk into a **wellâ€‘structured, researchâ€‘grade tour** that you can read, take notes, and apply.  

Weâ€™ll cover:  
1ï¸âƒ£ History & core ideas  
2ï¸âƒ£ Building blocks: embeddings, attention, feedâ€‘forward  
3ï¸âƒ£ Training dynamics and scaling laws  
4ï¸âƒ£ Realâ€‘world use cases  
5ï¸âƒ£ Advanced concepts (prefix tuning, bias, explainability)  
6ï¸âƒ£ Future research directions  
'''

result = chain.invoke({'text': text})

print(result)

# Visualise the chain
chain.get_graph().print_ascii()